AI vs Human Text Classification Using BERT  

Live Demo  
Try the app here -->  
[Try the AI vs Human Text Detection App](https://huggingface.co/spaces/Redfire-1234/AI_text_detection)  

 
References:  
- [PyTorch](https://pytorch.org/)  
- [Hugging Face — Transformers](https://huggingface.co/docs/transformers/index)  
- [Flask](https://flask.palletsprojects.com/)  
- [Docker](https://docs.docker.com/)  
- [scikit-learn](https://scikit-learn.org/)  
- [NumPy](https://numpy.org/) / [Pandas](https://pandas.pydata.org/)  



Project Overview: This project uses a fine‑tuned BERT model to classify whether a given text is written by a Human or generated by an AI system.   
A Dockerized Flask application is used to serve the model, allowing users to send text input and receive JSON‑based predictions along with confidence scores.   

Dataset:  
• Custom dataset created with both Human-written and AI-generated text.  
• Labels:  
  - 0 -> Human  
  - 1 -> AI   
• Dataset can be further expanded for improved performance.  

Preprocessing:  
• Text cleaning and normalization  
• Tokenization using BERT tokenizer  
• Train-Test split for evaluation  

Features:  

Model:  
• BERT (Bidirectional Encoder Representations from Transformers)  
• Fine-tuned for binary text classification  
• Softmax output for confidence score  

Flask + Docker Web App: • User sends text through API (POST request)  
• Model returns prediction (Human / AI)  
• Returns confidence probability  
• Containerized with Docker for consistent deployment  

Deployment (HuggingFace Spaces — Docker):  
• Container automatically built using Dockerfile  
• Public URL provided by HuggingFace  
• No need for ngrok or Streamlit Cloud  

Installation:  
Required Python Libraries:  
• torch  
• transformers  
• scikit-learn  
• pandas  
• numpy  
• flask   

Usage:  
Train Model:  
• Run training script to fine-tune BERT (if modification required)  

Run Flask App Locally:  
python app.py   
Build Docker Image:  
     docker build -t bert-detector .    
Run Docker Container:  
     docker run -p 7860:7860 bert-detector   

Deploy on HuggingFace:   
• Push code + Dockerfile to HuggingFace Space  
• HuggingFace automatically builds and hosts the container   

Saved Models:  
• BERT fine-tuned model: model.pth  
• Tokenizer files stored in working directory  

Results:  
• Predictions displayed with confidence score in UI  
• Streamlit output: “Human (xx%)” or “AI (xx%)”  
